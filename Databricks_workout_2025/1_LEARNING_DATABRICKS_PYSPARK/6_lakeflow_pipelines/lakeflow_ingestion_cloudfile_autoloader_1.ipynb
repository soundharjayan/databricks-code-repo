{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3091439-743f-49fc-afa0-7adee1a21ea0",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1770272678556}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from catalog1_we47.default.account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c60b2d07-3e25-4359-9cf9-81099e048779",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](/Workspace/Users/infoblisstech@gmail.com/databricks-code-repo/6_lakeflow_pipelines/autoloader_file_ingestion_usecase1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d85287e4-ec7b-4427-9d2f-2448171aa7cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Auto Loader is Databricks\n",
    "**Auto Loader is Databricksâ€™ cloud-native file ingestion engine for ingesting new files incrementally from object storage.**\n",
    "\n",
    "Supported Sources:\n",
    "- AWS S3\n",
    "- Azure ADLS Gen2\n",
    "- Google Cloud Storage (GCS)\n",
    "\n",
    "Modes:\n",
    "- Directory listing - Directory listing scans storage paths to detect new files (This works in free edition)\n",
    "- File notification - Processes files as soon as they arrive at scale (This will not work in free edition because the cloud storage event trigger can't control/trigger Databricks LF Ingestion)\n",
    "\n",
    "**Directory listing**\n",
    "1. Spark lists the Cloud directory (pull model)\n",
    "2. Detects new files\n",
    "3. Infers schema / evolves if needed\n",
    "4. Copy the file(s) & store the schema info in a schema file, so further schema inference is not needed.\n",
    "5. Updates checkpoint (file1 is processed...)\n",
    "6. Waits for next trigger of the Lakeflow pipeline\n",
    "\n",
    "**File Notification** (we will see it in the cloud databricks version)\n",
    "1. Cloud storage emits file-create event (S3 Event, ADLS Event Grid, GCS Pub/Sub)\n",
    "2. Event is delivered to Databricks queue\n",
    "3. Auto Loader receives notification (push model)\n",
    "4. New file is registered\n",
    "5. Infers schema / evolves if needed\n",
    "6. Copy the file(s) & store the schema info in a schema file, so further schema inference is not needed.\n",
    "7. Updates checkpoint (file1 is processed...)\n",
    "8. Stream stays idle until next event arrives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a01b7923-a4d8-4f3d-80dd-5c4ef09add16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**To perform schema evolution, we have to use the below properties:**<br>\n",
    "**Read side:** <br>\n",
    ".option(\"cloudFiles.schemaEvolutionMode\",\"addNewColumns\")<br>\n",
    "**Write side:** <br>\n",
    ".option(\"mergeSchema\", \"true\")<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfcc37fa-f40e-4216-99f9-e3cb83d1fec9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ckptlocation=\"/Volumes/catalog3_we47/schema3_we47/datalake/bronze/streamwrite13/_checkpoint\"\n",
    "schemalocation=\"/Volumes/catalog3_we47/schema3_we47/datalake/bronze/streamwrite54/_schema\"\n",
    "cloudsrc=\"/Volumes/catalog3_we47/schema3_we47/datalake/source2/\"#s3/gcs/adls/blob storage path\n",
    "bronzetgt=\"/Volumes/catalog3_we47/schema3_we47/datalake/bronze/streamwrite13/\"\n",
    "df1=spark.readStream.format(\"cloudFiles\")\\\n",
    ".option(\"cloudFiles.format\",\"csv\")\\\n",
    ".option(\"cloudFiles.maxFilesPerTrigger\",5)\\\n",
    ".option(\"cloudFiles.inferColumnTypes\",True)\\\n",
    ".option(\"cloudFiles.schemaEvolutionMode\",\"addNewColumns\")\\\n",
    ".option(\"checkpointLocation\", ckptlocation)\\\n",
    ".option(\"cloudFiles.schemaLocation\", schemalocation)\\\n",
    ".option(\"header\",True)\\\n",
    ".load(cloudsrc)#this can be s3/adls/gcs\n",
    "#.option(\"cloudFiles.useNotifications\", \"true\") (Remove this option to enable directory listing)\n",
    "#maxFilesPerTrigger - this property help spark to process howmany files in an iteration to control the resource utilization (all files will be processed ultimately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e4429e5-657c-4430-866d-166242c6ec80",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 4"
    }
   },
   "outputs": [],
   "source": [
    "#realtime trigger is not possible in free serverless\n",
    "df1.writeStream.trigger(availableNow=True)\\\n",
    ".option(\"checkpointLocation\", ckptlocation)\\\n",
    ".option(\"cloudFiles.schemaLocation\", schemalocation)\\\n",
    ".option(\"mergeSchema\", \"true\") \\\n",
    ".start(bronzetgt)\n",
    "#.option(\"mergeSchema\", \"true\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d17256ab-d5c4-4176-86b9-77aaee7dace5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.read.format(\"delta\").load(f\"/Volumes/catalog3_we47/schema3_we47/datalake/bronze/streamwrite13\").orderBy(\"city_name\").show(100)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7723175997136475,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "lakeflow_ingestion_cloudfile_autoloader_1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
